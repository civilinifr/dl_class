{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Lesson 1: Conceptual example of Deep Learning\n",
    "\n",
    "By Francesco Civilini revised by Zhuocheng Jiang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to neural nets\n",
    "A neural net is a set of connections uniting inputs and operations, usually displayed as a schematic of circles and lines. \n",
    "\n",
    "<img src=\"dl_intro_illustrator_edits\\2L_nn.ai.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many types of neural networks. This is a \"feedforward network\", which reads from left to right. Circles and lines correspond to neurons and synapses respectively. \n",
    "\n",
    "Each column of neurons is called a layer, of which there are \n",
    "- Input layer (3 neurons in above example)\n",
    "- Computation or \"hidden\" layer (2 neurons)\n",
    "- An output layer (1 neuron)\n",
    "\n",
    "The number of layers in the network is 2. The input layer does not count towards the total because it does not contain any trainable parameters. \n",
    "\n",
    "These models are simulated by the brain, where neurons are connected by dandrites (which bring input into the neuron) and axons (which bring output out of the neuron). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A closer look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dl_intro_illustrator_edits\\1in_1hid.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each synapse and neuron has a strength, and we call these **weights** and **biases** respectively. Both weights and biases are also known as the general term **parameters**. \n",
    "\n",
    "Components:\n",
    "- Input ($x$): Input value, for example, value of a pixel in an image. \n",
    "- Weight ($w$): Drives the scale of the input parameter\n",
    "- Bias ($b$): Translates or shifts the input\n",
    "- Computational node ($z$): Linear function combining inputs with weights and biases\n",
    "- Activation function ($a$): Non-linear function that affects the amplitude of the signal exciting a computaiton neuron. Without we would only be able to do linear maps. \n",
    "\n",
    "There are three main steps for deep learning modeling using neural nets:\n",
    "\n",
    "**(1) Define structure:**\n",
    "\n",
    "For this neural net, the computational node $z$ is the dot product between the input and weights added to the bias, or $z=x*w + b$.\n",
    "\n",
    "There are many different types of activation functions that can be used. A popular one is the sigmoid. Our output would then be as follows:\n",
    "\n",
    "output $= a(z)=\\frac{1}{1+e^-(z)}=\\frac{1}{1+e^-(xw + b)}$\n",
    "\n",
    "\n",
    "**(2) Error function:**\n",
    "\n",
    "In order to know how good of a fit our model is, we need to compare our results with a source of error. An error function that is pertinent to the problem is selected. \n",
    "\n",
    "\n",
    "**(3) Parameter update:**\n",
    "\n",
    "Continously update (modify) values of $w$ and $b$ such that error decreases. This process is done in deep learning by **stochastic gradient descent** and **backpropagation**. These processes use the gradient to determine the global minimum of the loss surface. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conceptual example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a very simple, yet valid special type of neural net called a **perceptron**. A perceptron is a neural net in which the output is binary. It returns True (output = 1) or False (output = 0). \n",
    "\n",
    "To make a clear example, we will simplify our neural net even further by (1) removing the activation function and (2) setting the bias as a threshold describing whether or not the neuron will fire.\n",
    "\n",
    "<img src=\"dl_intro_illustrator_edits\\perceptron.png\" style=\"width: 400px;\">\n",
    "\n",
    "where:\n",
    "\n",
    "$x*w <= b$ then output = 0\n",
    "\n",
    "$x*w > b$ then output = 1\n",
    "\n",
    "\n",
    "Assume that this is a model describing whether or not I want to go see a movie in a movie theater (remember when we used to do that?). In this example, $x$ is the only movie playing at the theater, $w$ describes how much I want to go see the movie, and $b$ is my \"lazyness threshold\". If my desire ($w$) to see the movie ($x$) is greater than my lazyness threshold ($b$), then we go to the movie theater. If not, we stay home. \n",
    "\n",
    "So what is $w$ mean in practice? Assume that $x$ is the movie *The Avengers*. The weight $w$ could represent how much I like superhero movies. If I like them a lot ($w$ is high), then it'll be more likely that I go to the theater. However, if I don't like superhero movies ($w$ is low), I'll probably stay home. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a two-movie example. \n",
    "<img src=\"dl_intro_illustrator_edits\\2in_1hid.png\" style=\"width: 350px;\">\n",
    "\n",
    "In this case:\n",
    "\n",
    "$x_1*w_1 + x_2*w_2  <= b$ then we stay home\n",
    "\n",
    "$x_1*w_1 + x_2*w_2  > b$ we go to the movies\n",
    "\n",
    "If we make $x_1$ is *The Avengers* and $x_2$ is *A Dog's Purpose*, $w_1$ could be how much we like superheroes and $w_2$ could be how much I like dogs. If I really dislike superheroes ($w_1$ is low) but I really love dogs ($w_2$ is high), I might still go to the movie theater. \n",
    "\n",
    "**The point:**\n",
    "If we have enough examples of movies playing in the movie theater and knowledge of whether or not I went to the movies (i.e. a training set), we can determine how much I like superheroes ($w_1$), dogs ($w_2$), and how lazy I am ($b$). Once we know these parameters, the neural net can be used to predict the outcome for a set of different movies. **This is the foundation of deep learning.**\n",
    "\n",
    "*A short note:*\n",
    "\n",
    "The inputs don't necessarily need to be related. For example, $x_1$ could be *The Avengers* and $x_2$ could be popcorn. Maybe I am not particularly excited about watching the movie, but I really want some popcorn, so I still go to the movie theater. Additionally, $x_1$ and $x_2$ could be vectors of values (i.e., lists of movies and concession snacks). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
